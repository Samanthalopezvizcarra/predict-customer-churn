# ğŸ“Š PredicciÃ³n de CancelaciÃ³n de Clientes

Este proyecto desarrolla y compara distintos modelos de **clasificaciÃ³n** para predecir la **cancelaciÃ³n de clientes** (churn). El enfoque se centra en obtener el mejor rendimiento posible optimizando la mÃ©trica **AUC ROC**, utilizando tÃ©cnicas avanzadas de preprocesamiento, balanceo, validaciÃ³n y tuning.

---

## ğŸš€ Objetivo del Proyecto
Predecir si un cliente cancelarÃ¡ su servicio (0/1) mediante modelos de machine learning que maximicen AUC ROC.  
Se implementÃ³ un flujo completo desde EDA hasta evaluaciÃ³n final, garantizando un proceso reproducible y libre de fugas de informaciÃ³n.

---

## ğŸ› ï¸ Pasos Realizados

### âœ”ï¸ PreparaciÃ³n y AnÃ¡lisis
- Carga y uniÃ³n de datos por **CustomerID**.  
- Preprocesamiento y creaciÃ³n de la variable objetivo.  
- Exploratory Data Analysis (EDA).  
- DivisiÃ³n en **train / validaciÃ³n / test**.  

### âœ”ï¸ Modelado
- CreaciÃ³n de **pipelines** para evitar data leakage.  
- Entrenamiento de modelos:
  - Dummy  
  - Random Forest  
  - LightGBM  
- AplicaciÃ³n de **SMOTE** para balanceo de clases.  
- Ajuste de hiperparÃ¡metros con **RandomizedSearchCV + validaciÃ³n cruzada estratificada**.  

### âœ”ï¸ EvaluaciÃ³n
- MÃ©tricas: **AUC ROC**, Accuracy.  
- Curvas ROC para comparar modelos.  

---

## âš™ï¸ Dificultades y Soluciones

### ğŸ”¹ Pipeline complejo  
Se organizaron etapas combinadas de preprocesamiento + SMOTE + modelo dentro de pipelines modulares para mantener el flujo limpio y reproducible.

### ğŸ”¹ PrevenciÃ³n de data leakage  
Todo escalado, codificaciÃ³n y balanceo se ajustÃ³ **solo con datos de entrenamiento** mediante pipelines correctamente estructurados.

### ğŸ”¹ Compatibilidad de funciones de evaluaciÃ³n  
Se creÃ³ una funciÃ³n estÃ¡ndar capaz de evaluar tanto modelos bÃ¡sicos como tunings, asegurando mÃ©tricas consistentes.

---

## â­ Resultados de Modelos

| Modelo | ConfiguraciÃ³n | AUC (ValidaciÃ³n) | Accuracy |
|-------|---------------|------------------|----------|
| Dummy | Base | 0.5000 | 0.7346 |
| RandomForest | Base | 0.9206 | 0.8772 |
| LightGBM | Base | 0.9580 | 0.9375 |
| RandomForest + SMOTE | Balanceado | 0.9161 | 0.8730 |
| LightGBM + SMOTE | Balanceado | 0.9617 | 0.9432 |
| RF + SMOTE + Tuning | Optimizado | 0.9168 | 0.8779 |
| LightGBM + SMOTE + Tuning | Optimizado | **0.9643** | **0.9454** |

---

## ğŸ† Modelo Final Seleccionado
**LightGBM + SMOTE + Tuning**

### ğŸ“ˆ Rendimiento en Test:
- **AUC:** 0.9640  
- **Accuracy:** 0.9390  

---

## ğŸ“Œ Conclusiones
- **LightGBM** fue el modelo con mejor desempeÃ±o general, combinando precisiÃ³n y rapidez.  
- **SMOTE** mejorÃ³ ligeramente los resultados, confirmando un desbalance moderado en las clases.  
- El tuning con RandomizedSearchCV incrementÃ³ la estabilidad y rendimiento del modelo.  
- El uso de **pipelines modulares** garantiza reproducibilidad, escalabilidad y evita data leakage.

---
